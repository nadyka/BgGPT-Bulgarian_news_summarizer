{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, I can help you with that. Here's a step-by-step guide along with Python code to implement your project:\n",
    "\n",
    "Step 1: Retrieve the 10 most recent news articles\n",
    "You can use web scraping libraries like BeautifulSoup or Scrapy to extract the news articles from the specified website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_recent_articles(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('article')[:10]  # Assuming articles are wrapped in <article> tags\n",
    "    return articles\n",
    "\n",
    "articles = get_recent_articles(\"https://www.mediapool.bg/news/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Summarize each article using BgGPT\n",
    "You can use the OpenAI API to summarize each article. Make sure you have your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "def summarize_article(article_text):\n",
    "    summary = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=article_text,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return summary.choices[0].text.strip()\n",
    "\n",
    "summaries = []\n",
    "for article in articles:\n",
    "    article_text = article.find('div', class_='article-text').text  # Assuming article text is inside a div with class 'article-text'\n",
    "    summary = summarize_article(article_text)\n",
    "    summaries.append(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Present the articles in Streamlit GUI\n",
    "You can use Streamlit to create a user interface to display the articles and summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def display_articles_with_summaries(articles, summaries):\n",
    "    for i, article in enumerate(articles):\n",
    "        st.title(f\"Article {i+1}\")\n",
    "        st.write(f\"Title: {article.find('h2').text}\")  # Assuming article title is inside an h2 tag\n",
    "        st.write(f\"Summary: {summaries[i]}\")\n",
    "        st.write(f\"Read more: {article.find('a')['href']}\")  # Assuming article link is inside an <a> tag\n",
    "        st.write(\"----\")\n",
    "\n",
    "display_articles_with_summaries(articles, summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Retrieve articles periodically\n",
    "You can use a scheduler like schedule to retrieve articles at specific times.\n",
    "\n",
    "Step 5: Store articles\n",
    "You can store articles and their summaries in SQLite database or in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('articles.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS articles\n",
    "             (id INTEGER PRIMARY KEY, title TEXT, summary TEXT, link TEXT)''')\n",
    "\n",
    "
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
